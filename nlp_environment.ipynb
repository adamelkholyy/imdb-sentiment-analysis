{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sentiment Analysis</h1><br>\n",
    "2023 NLP Coursework Part A. First we must import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adame\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adame\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\adame\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_corpus(directory):\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "    corpus = []\n",
    "    for file in files:\n",
    "        with open(os.path.join(directory, file), 'r', encoding='utf-8') as f:\n",
    "            document = f.read()\n",
    "            corpus.append(document)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they'll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it's like to be homeless? That is Goddard Bolt's lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet's on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can't step off the sidewalk. He's given the nickname Pepto by a vagrant after it's written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They're survivors. Bolt isn't. He's not used to reaching mutual agreements like he once did when being rich where it's fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn't necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it's like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don't know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others.\n",
      "This film is about a male escort getting involved in a murder investigation that happened in the circle of powerful men's wives.<br /><br />I thought \"The Walker\" would be thrilling and engaging, but I was so wrong. The pacing is painfully and excruciatingly slow, that even after 40 minutes of the film nothing happens much. Seriously, the first hour could be condensed into ten minutes. That's how slow it is.<br /><br />The fact that it lacks any thrills or action scenes aggravates the boredom. It's almost shocking that even argument scenes are so plain and devoid of emotion. Maybe it is because of the stiff upper lip of the higher social class? <br /><br />It's sad that \"The Walker\" becomes such a boring mess, despite such a strong cast. Blame it on the poor plot and even worse pacing.\n"
     ]
    }
   ],
   "source": [
    "positive_corpus = read_corpus(\"data/pos/\")\n",
    "negative_corpus = read_corpus(\"data/neg/\")\n",
    "corpus = positive_corpus + negative_corpus\n",
    "positive_labels = len(positive_corpus)\n",
    "negative_labels = len(negative_corpus)\n",
    "corpus_length = len(corpus)\n",
    "\n",
    "#sanity check, should be the same every time\n",
    "print(positive_corpus[0])\n",
    "print(negative_corpus[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Feature Generation Using Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import ngrams\n",
    "\n",
    "def text_to_ngrams(sentence, n, remove_stopwords=True):\n",
    "    stoplist = set(stopwords.words('english')) #stop-words to remove\n",
    "    if not remove_stopwords:\n",
    "        stoplist = set()\n",
    "    tokenised_words = [word for word in word_tokenize(sentence.lower()) if word not in stoplist and word not in string.punctuation\n",
    "                       and word != \"br\"] \n",
    "                    #a list of tokenised words with stop-words, punctuation, and <br>s removed\n",
    "    zipped_grams = ngrams(tokenised_words, n) #apply nltk's ngrams algorithm\n",
    "    return list(zipped_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ozymandias', 'king', 'kings'), ('king', 'kings', 'look'), ('kings', 'look', 'upon'), ('look', 'upon', 'works'), ('upon', 'works', 'ye'), ('works', 'ye', 'mighty'), ('ye', 'mighty', 'despair')]\n",
      "('ozymandias', 'king', 'kings')\n",
      "('king', 'kings', 'look')\n",
      "('kings', 'look', 'upon')\n",
      "('look', 'upon', 'works')\n",
      "('upon', 'works', 'ye')\n",
      "('works', 'ye', 'mighty')\n",
      "('ye', 'mighty', 'despair')\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I am Ozymandias, king of kings, look upon my works ye mighty and despair\"\n",
    "grams = text_to_ngrams(sentence, 3)\n",
    "print(grams)\n",
    "for gram in grams:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts the entire corpus to ngrams\n",
    "def corpus_to_ngrams(corpus, n, remove_stopwords=True):\n",
    "    new_corpus = []\n",
    "    for text in corpus:\n",
    "        new_corpus.append(text_to_ngrams(text, n, remove_stopwords))\n",
    "    return new_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('homelessness',), ('houselessness',), ('george',), ('carlin',), ('stated',), ('issue',), ('years',), ('never',), ('plan',), ('help',), ('street',), ('considered',), ('human',), ('everything',), ('going',), ('school',), ('work',), ('vote',), ('matter',), ('people',), ('think',), ('homeless',), ('lost',), ('cause',), ('worrying',), ('things',), ('racism',), ('war',), ('iraq',), ('pressuring',), ('kids',), ('succeed',), ('technology',), ('elections',), ('inflation',), ('worrying',), (\"'ll\",), ('next',), ('end',), ('streets.',), ('given',), ('bet',), ('live',), ('streets',), ('month',), ('without',), ('luxuries',), ('home',), ('entertainment',), ('sets',), ('bathroom',), ('pictures',), ('wall',), ('computer',), ('everything',), ('treasure',), ('see',), (\"'s\",), ('like',), ('homeless',), ('goddard',), ('bolt',), (\"'s\",), ('lesson.',), ('mel',), ('brooks',), ('directs',), ('stars',), ('bolt',), ('plays',), ('rich',), ('man',), ('everything',), ('world',), ('deciding',), ('make',), ('bet',), ('sissy',), ('rival',), ('jeffery',), ('tambor',), ('see',), ('live',), ('streets',), ('thirty',), ('days',), ('without',), ('luxuries',), ('bolt',), ('succeeds',), ('wants',), ('future',), ('project',), ('making',), ('buildings',), ('bet',), (\"'s\",), ('bolt',), ('thrown',), ('street',), ('bracelet',), ('leg',), ('monitor',), ('every',), ('move',), ('ca',), (\"n't\",), ('step',), ('sidewalk',), (\"'s\",), ('given',), ('nickname',), ('pepto',), ('vagrant',), (\"'s\",), ('written',), ('forehead',), ('bolt',), ('meets',), ('characters',), ('including',), ('woman',), ('name',), ('molly',), ('lesley',), ('ann',), ('warren',), ('ex-dancer',), ('got',), ('divorce',), ('losing',), ('home',), ('pals',), ('sailor',), ('howard',), ('morris',), ('fumes',), ('teddy',), ('wilson',), ('already',), ('used',), ('streets',), (\"'re\",), ('survivors',), ('bolt',), (\"n't\",), (\"'s\",), ('used',), ('reaching',), ('mutual',), ('agreements',), ('like',), ('rich',), (\"'s\",), ('fight',), ('flight',), ('kill',), ('killed.',), ('love',), ('connection',), ('molly',), ('bolt',), (\"n't\",), ('necessary',), ('plot',), ('found',), ('``',), ('life',), ('stinks',), (\"''\",), ('one',), ('mel',), ('brooks',), ('observant',), ('films',), ('prior',), ('comedy',), ('shows',), ('tender',), ('side',), ('compared',), ('slapstick',), ('work',), ('blazing',), ('saddles',), ('young',), ('frankenstein',), ('spaceballs',), ('matter',), ('show',), (\"'s\",), ('like',), ('something',), ('valuable',), ('losing',), ('next',), ('day',), ('hand',), ('making',), ('stupid',), ('bet',), ('like',), ('rich',), ('people',), (\"n't\",), ('know',), ('money',), ('maybe',), ('give',), ('homeless',), ('instead',), ('using',), ('like',), ('monopoly',), ('money.',), ('maybe',), ('film',), ('inspire',), ('help',), ('others',)]\n"
     ]
    }
   ],
   "source": [
    "corpus_unigrams = corpus_to_ngrams(corpus, 1)\n",
    "print(corpus_unigrams[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('homelessness', 'houselessness'), ('houselessness', 'george'), ('george', 'carlin'), ('carlin', 'stated'), ('stated', 'issue'), ('issue', 'years'), ('years', 'never'), ('never', 'plan'), ('plan', 'help'), ('help', 'street'), ('street', 'considered'), ('considered', 'human'), ('human', 'everything'), ('everything', 'going'), ('going', 'school'), ('school', 'work'), ('work', 'vote'), ('vote', 'matter'), ('matter', 'people'), ('people', 'think'), ('think', 'homeless'), ('homeless', 'lost'), ('lost', 'cause'), ('cause', 'worrying'), ('worrying', 'things'), ('things', 'racism'), ('racism', 'war'), ('war', 'iraq'), ('iraq', 'pressuring'), ('pressuring', 'kids'), ('kids', 'succeed'), ('succeed', 'technology'), ('technology', 'elections'), ('elections', 'inflation'), ('inflation', 'worrying'), ('worrying', \"'ll\"), (\"'ll\", 'next'), ('next', 'end'), ('end', 'streets.'), ('streets.', 'given'), ('given', 'bet'), ('bet', 'live'), ('live', 'streets'), ('streets', 'month'), ('month', 'without'), ('without', 'luxuries'), ('luxuries', 'home'), ('home', 'entertainment'), ('entertainment', 'sets'), ('sets', 'bathroom'), ('bathroom', 'pictures'), ('pictures', 'wall'), ('wall', 'computer'), ('computer', 'everything'), ('everything', 'treasure'), ('treasure', 'see'), ('see', \"'s\"), (\"'s\", 'like'), ('like', 'homeless'), ('homeless', 'goddard'), ('goddard', 'bolt'), ('bolt', \"'s\"), (\"'s\", 'lesson.'), ('lesson.', 'mel'), ('mel', 'brooks'), ('brooks', 'directs'), ('directs', 'stars'), ('stars', 'bolt'), ('bolt', 'plays'), ('plays', 'rich'), ('rich', 'man'), ('man', 'everything'), ('everything', 'world'), ('world', 'deciding'), ('deciding', 'make'), ('make', 'bet'), ('bet', 'sissy'), ('sissy', 'rival'), ('rival', 'jeffery'), ('jeffery', 'tambor'), ('tambor', 'see'), ('see', 'live'), ('live', 'streets'), ('streets', 'thirty'), ('thirty', 'days'), ('days', 'without'), ('without', 'luxuries'), ('luxuries', 'bolt'), ('bolt', 'succeeds'), ('succeeds', 'wants'), ('wants', 'future'), ('future', 'project'), ('project', 'making'), ('making', 'buildings'), ('buildings', 'bet'), ('bet', \"'s\"), (\"'s\", 'bolt'), ('bolt', 'thrown'), ('thrown', 'street'), ('street', 'bracelet'), ('bracelet', 'leg'), ('leg', 'monitor'), ('monitor', 'every'), ('every', 'move'), ('move', 'ca'), ('ca', \"n't\"), (\"n't\", 'step'), ('step', 'sidewalk'), ('sidewalk', \"'s\"), (\"'s\", 'given'), ('given', 'nickname'), ('nickname', 'pepto'), ('pepto', 'vagrant'), ('vagrant', \"'s\"), (\"'s\", 'written'), ('written', 'forehead'), ('forehead', 'bolt'), ('bolt', 'meets'), ('meets', 'characters'), ('characters', 'including'), ('including', 'woman'), ('woman', 'name'), ('name', 'molly'), ('molly', 'lesley'), ('lesley', 'ann'), ('ann', 'warren'), ('warren', 'ex-dancer'), ('ex-dancer', 'got'), ('got', 'divorce'), ('divorce', 'losing'), ('losing', 'home'), ('home', 'pals'), ('pals', 'sailor'), ('sailor', 'howard'), ('howard', 'morris'), ('morris', 'fumes'), ('fumes', 'teddy'), ('teddy', 'wilson'), ('wilson', 'already'), ('already', 'used'), ('used', 'streets'), ('streets', \"'re\"), (\"'re\", 'survivors'), ('survivors', 'bolt'), ('bolt', \"n't\"), (\"n't\", \"'s\"), (\"'s\", 'used'), ('used', 'reaching'), ('reaching', 'mutual'), ('mutual', 'agreements'), ('agreements', 'like'), ('like', 'rich'), ('rich', \"'s\"), (\"'s\", 'fight'), ('fight', 'flight'), ('flight', 'kill'), ('kill', 'killed.'), ('killed.', 'love'), ('love', 'connection'), ('connection', 'molly'), ('molly', 'bolt'), ('bolt', \"n't\"), (\"n't\", 'necessary'), ('necessary', 'plot'), ('plot', 'found'), ('found', '``'), ('``', 'life'), ('life', 'stinks'), ('stinks', \"''\"), (\"''\", 'one'), ('one', 'mel'), ('mel', 'brooks'), ('brooks', 'observant'), ('observant', 'films'), ('films', 'prior'), ('prior', 'comedy'), ('comedy', 'shows'), ('shows', 'tender'), ('tender', 'side'), ('side', 'compared'), ('compared', 'slapstick'), ('slapstick', 'work'), ('work', 'blazing'), ('blazing', 'saddles'), ('saddles', 'young'), ('young', 'frankenstein'), ('frankenstein', 'spaceballs'), ('spaceballs', 'matter'), ('matter', 'show'), ('show', \"'s\"), (\"'s\", 'like'), ('like', 'something'), ('something', 'valuable'), ('valuable', 'losing'), ('losing', 'next'), ('next', 'day'), ('day', 'hand'), ('hand', 'making'), ('making', 'stupid'), ('stupid', 'bet'), ('bet', 'like'), ('like', 'rich'), ('rich', 'people'), ('people', \"n't\"), (\"n't\", 'know'), ('know', 'money'), ('money', 'maybe'), ('maybe', 'give'), ('give', 'homeless'), ('homeless', 'instead'), ('instead', 'using'), ('using', 'like'), ('like', 'monopoly'), ('monopoly', 'money.'), ('money.', 'maybe'), ('maybe', 'film'), ('film', 'inspire'), ('inspire', 'help'), ('help', 'others')]\n"
     ]
    }
   ],
   "source": [
    "corpus_bigrams = corpus_to_ngrams(corpus, 2)\n",
    "print(corpus_bigrams[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('homelessness', 'houselessness', 'george'), ('houselessness', 'george', 'carlin'), ('george', 'carlin', 'stated'), ('carlin', 'stated', 'issue'), ('stated', 'issue', 'years'), ('issue', 'years', 'never'), ('years', 'never', 'plan'), ('never', 'plan', 'help'), ('plan', 'help', 'street'), ('help', 'street', 'considered'), ('street', 'considered', 'human'), ('considered', 'human', 'everything'), ('human', 'everything', 'going'), ('everything', 'going', 'school'), ('going', 'school', 'work'), ('school', 'work', 'vote'), ('work', 'vote', 'matter'), ('vote', 'matter', 'people'), ('matter', 'people', 'think'), ('people', 'think', 'homeless'), ('think', 'homeless', 'lost'), ('homeless', 'lost', 'cause'), ('lost', 'cause', 'worrying'), ('cause', 'worrying', 'things'), ('worrying', 'things', 'racism'), ('things', 'racism', 'war'), ('racism', 'war', 'iraq'), ('war', 'iraq', 'pressuring'), ('iraq', 'pressuring', 'kids'), ('pressuring', 'kids', 'succeed'), ('kids', 'succeed', 'technology'), ('succeed', 'technology', 'elections'), ('technology', 'elections', 'inflation'), ('elections', 'inflation', 'worrying'), ('inflation', 'worrying', \"'ll\"), ('worrying', \"'ll\", 'next'), (\"'ll\", 'next', 'end'), ('next', 'end', 'streets.'), ('end', 'streets.', 'given'), ('streets.', 'given', 'bet'), ('given', 'bet', 'live'), ('bet', 'live', 'streets'), ('live', 'streets', 'month'), ('streets', 'month', 'without'), ('month', 'without', 'luxuries'), ('without', 'luxuries', 'home'), ('luxuries', 'home', 'entertainment'), ('home', 'entertainment', 'sets'), ('entertainment', 'sets', 'bathroom'), ('sets', 'bathroom', 'pictures'), ('bathroom', 'pictures', 'wall'), ('pictures', 'wall', 'computer'), ('wall', 'computer', 'everything'), ('computer', 'everything', 'treasure'), ('everything', 'treasure', 'see'), ('treasure', 'see', \"'s\"), ('see', \"'s\", 'like'), (\"'s\", 'like', 'homeless'), ('like', 'homeless', 'goddard'), ('homeless', 'goddard', 'bolt'), ('goddard', 'bolt', \"'s\"), ('bolt', \"'s\", 'lesson.'), (\"'s\", 'lesson.', 'mel'), ('lesson.', 'mel', 'brooks'), ('mel', 'brooks', 'directs'), ('brooks', 'directs', 'stars'), ('directs', 'stars', 'bolt'), ('stars', 'bolt', 'plays'), ('bolt', 'plays', 'rich'), ('plays', 'rich', 'man'), ('rich', 'man', 'everything'), ('man', 'everything', 'world'), ('everything', 'world', 'deciding'), ('world', 'deciding', 'make'), ('deciding', 'make', 'bet'), ('make', 'bet', 'sissy'), ('bet', 'sissy', 'rival'), ('sissy', 'rival', 'jeffery'), ('rival', 'jeffery', 'tambor'), ('jeffery', 'tambor', 'see'), ('tambor', 'see', 'live'), ('see', 'live', 'streets'), ('live', 'streets', 'thirty'), ('streets', 'thirty', 'days'), ('thirty', 'days', 'without'), ('days', 'without', 'luxuries'), ('without', 'luxuries', 'bolt'), ('luxuries', 'bolt', 'succeeds'), ('bolt', 'succeeds', 'wants'), ('succeeds', 'wants', 'future'), ('wants', 'future', 'project'), ('future', 'project', 'making'), ('project', 'making', 'buildings'), ('making', 'buildings', 'bet'), ('buildings', 'bet', \"'s\"), ('bet', \"'s\", 'bolt'), (\"'s\", 'bolt', 'thrown'), ('bolt', 'thrown', 'street'), ('thrown', 'street', 'bracelet'), ('street', 'bracelet', 'leg'), ('bracelet', 'leg', 'monitor'), ('leg', 'monitor', 'every'), ('monitor', 'every', 'move'), ('every', 'move', 'ca'), ('move', 'ca', \"n't\"), ('ca', \"n't\", 'step'), (\"n't\", 'step', 'sidewalk'), ('step', 'sidewalk', \"'s\"), ('sidewalk', \"'s\", 'given'), (\"'s\", 'given', 'nickname'), ('given', 'nickname', 'pepto'), ('nickname', 'pepto', 'vagrant'), ('pepto', 'vagrant', \"'s\"), ('vagrant', \"'s\", 'written'), (\"'s\", 'written', 'forehead'), ('written', 'forehead', 'bolt'), ('forehead', 'bolt', 'meets'), ('bolt', 'meets', 'characters'), ('meets', 'characters', 'including'), ('characters', 'including', 'woman'), ('including', 'woman', 'name'), ('woman', 'name', 'molly'), ('name', 'molly', 'lesley'), ('molly', 'lesley', 'ann'), ('lesley', 'ann', 'warren'), ('ann', 'warren', 'ex-dancer'), ('warren', 'ex-dancer', 'got'), ('ex-dancer', 'got', 'divorce'), ('got', 'divorce', 'losing'), ('divorce', 'losing', 'home'), ('losing', 'home', 'pals'), ('home', 'pals', 'sailor'), ('pals', 'sailor', 'howard'), ('sailor', 'howard', 'morris'), ('howard', 'morris', 'fumes'), ('morris', 'fumes', 'teddy'), ('fumes', 'teddy', 'wilson'), ('teddy', 'wilson', 'already'), ('wilson', 'already', 'used'), ('already', 'used', 'streets'), ('used', 'streets', \"'re\"), ('streets', \"'re\", 'survivors'), (\"'re\", 'survivors', 'bolt'), ('survivors', 'bolt', \"n't\"), ('bolt', \"n't\", \"'s\"), (\"n't\", \"'s\", 'used'), (\"'s\", 'used', 'reaching'), ('used', 'reaching', 'mutual'), ('reaching', 'mutual', 'agreements'), ('mutual', 'agreements', 'like'), ('agreements', 'like', 'rich'), ('like', 'rich', \"'s\"), ('rich', \"'s\", 'fight'), (\"'s\", 'fight', 'flight'), ('fight', 'flight', 'kill'), ('flight', 'kill', 'killed.'), ('kill', 'killed.', 'love'), ('killed.', 'love', 'connection'), ('love', 'connection', 'molly'), ('connection', 'molly', 'bolt'), ('molly', 'bolt', \"n't\"), ('bolt', \"n't\", 'necessary'), (\"n't\", 'necessary', 'plot'), ('necessary', 'plot', 'found'), ('plot', 'found', '``'), ('found', '``', 'life'), ('``', 'life', 'stinks'), ('life', 'stinks', \"''\"), ('stinks', \"''\", 'one'), (\"''\", 'one', 'mel'), ('one', 'mel', 'brooks'), ('mel', 'brooks', 'observant'), ('brooks', 'observant', 'films'), ('observant', 'films', 'prior'), ('films', 'prior', 'comedy'), ('prior', 'comedy', 'shows'), ('comedy', 'shows', 'tender'), ('shows', 'tender', 'side'), ('tender', 'side', 'compared'), ('side', 'compared', 'slapstick'), ('compared', 'slapstick', 'work'), ('slapstick', 'work', 'blazing'), ('work', 'blazing', 'saddles'), ('blazing', 'saddles', 'young'), ('saddles', 'young', 'frankenstein'), ('young', 'frankenstein', 'spaceballs'), ('frankenstein', 'spaceballs', 'matter'), ('spaceballs', 'matter', 'show'), ('matter', 'show', \"'s\"), ('show', \"'s\", 'like'), (\"'s\", 'like', 'something'), ('like', 'something', 'valuable'), ('something', 'valuable', 'losing'), ('valuable', 'losing', 'next'), ('losing', 'next', 'day'), ('next', 'day', 'hand'), ('day', 'hand', 'making'), ('hand', 'making', 'stupid'), ('making', 'stupid', 'bet'), ('stupid', 'bet', 'like'), ('bet', 'like', 'rich'), ('like', 'rich', 'people'), ('rich', 'people', \"n't\"), ('people', \"n't\", 'know'), (\"n't\", 'know', 'money'), ('know', 'money', 'maybe'), ('money', 'maybe', 'give'), ('maybe', 'give', 'homeless'), ('give', 'homeless', 'instead'), ('homeless', 'instead', 'using'), ('instead', 'using', 'like'), ('using', 'like', 'monopoly'), ('like', 'monopoly', 'money.'), ('monopoly', 'money.', 'maybe'), ('money.', 'maybe', 'film'), ('maybe', 'film', 'inspire'), ('film', 'inspire', 'help'), ('inspire', 'help', 'others')]\n"
     ]
    }
   ],
   "source": [
    "corpus_trigrams = corpus_to_ngrams(corpus, 3)\n",
    "print(corpus_trigrams[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('homelessness',), ('or',), ('houselessness',), ('as',), ('george',), ('carlin',), ('stated',), ('has',), ('been',), ('an',), ('issue',), ('for',), ('years',), ('but',), ('never',), ('a',), ('plan',), ('to',), ('help',), ('those',), ('on',), ('the',), ('street',), ('that',), ('were',), ('once',), ('considered',), ('human',), ('who',), ('did',), ('everything',), ('from',), ('going',), ('to',), ('school',), ('work',), ('or',), ('vote',), ('for',), ('the',), ('matter',), ('most',), ('people',), ('think',), ('of',), ('the',), ('homeless',), ('as',), ('just',), ('a',), ('lost',), ('cause',), ('while',), ('worrying',), ('about',), ('things',), ('such',), ('as',), ('racism',), ('the',), ('war',), ('on',), ('iraq',), ('pressuring',), ('kids',), ('to',), ('succeed',), ('technology',), ('the',), ('elections',), ('inflation',), ('or',), ('worrying',), ('if',), ('they',), (\"'ll\",), ('be',), ('next',), ('to',), ('end',), ('up',), ('on',), ('the',), ('streets.',), ('but',), ('what',), ('if',), ('you',), ('were',), ('given',), ('a',), ('bet',), ('to',), ('live',), ('on',), ('the',), ('streets',), ('for',), ('a',), ('month',), ('without',), ('the',), ('luxuries',), ('you',), ('once',), ('had',), ('from',), ('a',), ('home',), ('the',), ('entertainment',), ('sets',), ('a',), ('bathroom',), ('pictures',), ('on',), ('the',), ('wall',), ('a',), ('computer',), ('and',), ('everything',), ('you',), ('once',), ('treasure',), ('to',), ('see',), ('what',), ('it',), (\"'s\",), ('like',), ('to',), ('be',), ('homeless',), ('that',), ('is',), ('goddard',), ('bolt',), (\"'s\",), ('lesson.',), ('mel',), ('brooks',), ('who',), ('directs',), ('who',), ('stars',), ('as',), ('bolt',), ('plays',), ('a',), ('rich',), ('man',), ('who',), ('has',), ('everything',), ('in',), ('the',), ('world',), ('until',), ('deciding',), ('to',), ('make',), ('a',), ('bet',), ('with',), ('a',), ('sissy',), ('rival',), ('jeffery',), ('tambor',), ('to',), ('see',), ('if',), ('he',), ('can',), ('live',), ('in',), ('the',), ('streets',), ('for',), ('thirty',), ('days',), ('without',), ('the',), ('luxuries',), ('if',), ('bolt',), ('succeeds',), ('he',), ('can',), ('do',), ('what',), ('he',), ('wants',), ('with',), ('a',), ('future',), ('project',), ('of',), ('making',), ('more',), ('buildings',), ('the',), ('bet',), (\"'s\",), ('on',), ('where',), ('bolt',), ('is',), ('thrown',), ('on',), ('the',), ('street',), ('with',), ('a',), ('bracelet',), ('on',), ('his',), ('leg',), ('to',), ('monitor',), ('his',), ('every',), ('move',), ('where',), ('he',), ('ca',), (\"n't\",), ('step',), ('off',), ('the',), ('sidewalk',), ('he',), (\"'s\",), ('given',), ('the',), ('nickname',), ('pepto',), ('by',), ('a',), ('vagrant',), ('after',), ('it',), (\"'s\",), ('written',), ('on',), ('his',), ('forehead',), ('where',), ('bolt',), ('meets',), ('other',), ('characters',), ('including',), ('a',), ('woman',), ('by',), ('the',), ('name',), ('of',), ('molly',), ('lesley',), ('ann',), ('warren',), ('an',), ('ex-dancer',), ('who',), ('got',), ('divorce',), ('before',), ('losing',), ('her',), ('home',), ('and',), ('her',), ('pals',), ('sailor',), ('howard',), ('morris',), ('and',), ('fumes',), ('teddy',), ('wilson',), ('who',), ('are',), ('already',), ('used',), ('to',), ('the',), ('streets',), ('they',), (\"'re\",), ('survivors',), ('bolt',), ('is',), (\"n't\",), ('he',), (\"'s\",), ('not',), ('used',), ('to',), ('reaching',), ('mutual',), ('agreements',), ('like',), ('he',), ('once',), ('did',), ('when',), ('being',), ('rich',), ('where',), ('it',), (\"'s\",), ('fight',), ('or',), ('flight',), ('kill',), ('or',), ('be',), ('killed.',), ('while',), ('the',), ('love',), ('connection',), ('between',), ('molly',), ('and',), ('bolt',), ('was',), (\"n't\",), ('necessary',), ('to',), ('plot',), ('i',), ('found',), ('``',), ('life',), ('stinks',), (\"''\",), ('to',), ('be',), ('one',), ('of',), ('mel',), ('brooks',), ('observant',), ('films',), ('where',), ('prior',), ('to',), ('being',), ('a',), ('comedy',), ('it',), ('shows',), ('a',), ('tender',), ('side',), ('compared',), ('to',), ('his',), ('slapstick',), ('work',), ('such',), ('as',), ('blazing',), ('saddles',), ('young',), ('frankenstein',), ('or',), ('spaceballs',), ('for',), ('the',), ('matter',), ('to',), ('show',), ('what',), ('it',), (\"'s\",), ('like',), ('having',), ('something',), ('valuable',), ('before',), ('losing',), ('it',), ('the',), ('next',), ('day',), ('or',), ('on',), ('the',), ('other',), ('hand',), ('making',), ('a',), ('stupid',), ('bet',), ('like',), ('all',), ('rich',), ('people',), ('do',), ('when',), ('they',), ('do',), (\"n't\",), ('know',), ('what',), ('to',), ('do',), ('with',), ('their',), ('money',), ('maybe',), ('they',), ('should',), ('give',), ('it',), ('to',), ('the',), ('homeless',), ('instead',), ('of',), ('using',), ('it',), ('like',), ('monopoly',), ('money.',), ('or',), ('maybe',), ('this',), ('film',), ('will',), ('inspire',), ('you',), ('to',), ('help',), ('others',)]\n"
     ]
    }
   ],
   "source": [
    "corps_unigrams_with_stopwords = corpus_to_ngrams(corpus, 1, remove_stopwords=False)\n",
    "print(corps_unigrams_with_stopwords[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Feature Selection using Lemmatization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(text):\n",
    "    st = LancasterStemmer()\n",
    "    word_list = [\" \".join(st.stem(gram) for gram in ngram) for ngram in text]\n",
    "                # stems the list of ngram tuples using nltk's LancasterStemmer\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ozymandia king king\n",
      "king king look\n",
      "king look upon\n",
      "look upon work\n",
      "upon work ye\n",
      "work ye mighty\n",
      "ye mighty despair\n"
     ]
    }
   ],
   "source": [
    "stemmed_text = apply_stemming(grams)\n",
    "for feature in stemmed_text:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lemmatization(text):\n",
    "    lm = WordNetLemmatizer()\n",
    "    word_list = [\" \".join(lm.lemmatize(gram) for gram in ngram) for ngram in text]\n",
    "                # lemmatizes the list of ngram tuples\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ozymandias king king\n",
      "king king look\n",
      "king look upon\n",
      "look upon work\n",
      "upon work ye\n",
      "work ye mighty\n",
      "ye mighty despair\n"
     ]
    }
   ],
   "source": [
    "lemmatized_text = apply_lemmatization(grams)\n",
    "for feature in lemmatized_text:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply a given stemming or lemmatization function to the corpus\n",
    "def apply_to_corpus(func, corpus):\n",
    "    new_corpus = []\n",
    "    for text in corpus:\n",
    "        new_corpus.append(func(text))\n",
    "    return new_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['homelessness', 'houselessness', 'george', 'carlin', 'stated', 'issue', 'year', 'never', 'plan', 'help', 'street', 'considered', 'human', 'everything', 'going', 'school', 'work', 'vote', 'matter', 'people', 'think', 'homeless', 'lost', 'cause', 'worrying', 'thing', 'racism', 'war', 'iraq', 'pressuring', 'kid', 'succeed', 'technology', 'election', 'inflation', 'worrying', \"'ll\", 'next', 'end', 'streets.', 'given', 'bet', 'live', 'street', 'month', 'without', 'luxury', 'home', 'entertainment', 'set', 'bathroom', 'picture', 'wall', 'computer', 'everything', 'treasure', 'see', \"'s\", 'like', 'homeless', 'goddard', 'bolt', \"'s\", 'lesson.', 'mel', 'brook', 'directs', 'star', 'bolt', 'play', 'rich', 'man', 'everything', 'world', 'deciding', 'make', 'bet', 'sissy', 'rival', 'jeffery', 'tambor', 'see', 'live', 'street', 'thirty', 'day', 'without', 'luxury', 'bolt', 'succeeds', 'want', 'future', 'project', 'making', 'building', 'bet', \"'s\", 'bolt', 'thrown', 'street', 'bracelet', 'leg', 'monitor', 'every', 'move', 'ca', \"n't\", 'step', 'sidewalk', \"'s\", 'given', 'nickname', 'pepto', 'vagrant', \"'s\", 'written', 'forehead', 'bolt', 'meet', 'character', 'including', 'woman', 'name', 'molly', 'lesley', 'ann', 'warren', 'ex-dancer', 'got', 'divorce', 'losing', 'home', 'pal', 'sailor', 'howard', 'morris', 'fume', 'teddy', 'wilson', 'already', 'used', 'street', \"'re\", 'survivor', 'bolt', \"n't\", \"'s\", 'used', 'reaching', 'mutual', 'agreement', 'like', 'rich', \"'s\", 'fight', 'flight', 'kill', 'killed.', 'love', 'connection', 'molly', 'bolt', \"n't\", 'necessary', 'plot', 'found', '``', 'life', 'stink', \"''\", 'one', 'mel', 'brook', 'observant', 'film', 'prior', 'comedy', 'show', 'tender', 'side', 'compared', 'slapstick', 'work', 'blazing', 'saddle', 'young', 'frankenstein', 'spaceballs', 'matter', 'show', \"'s\", 'like', 'something', 'valuable', 'losing', 'next', 'day', 'hand', 'making', 'stupid', 'bet', 'like', 'rich', 'people', \"n't\", 'know', 'money', 'maybe', 'give', 'homeless', 'instead', 'using', 'like', 'monopoly', 'money.', 'maybe', 'film', 'inspire', 'help', 'others']\n",
      "['homeless', 'houseless', 'georg', 'carlin', 'stat', 'issu', 'year', 'nev', 'plan', 'help', 'street', 'consid', 'hum', 'everyth', 'going', 'school', 'work', 'vot', 'mat', 'peopl', 'think', 'homeless', 'lost', 'caus', 'worry', 'thing', 'rac', 'war', 'iraq', 'press', 'kid', 'success', 'technolog', 'elect', 'infl', 'worry', \"'ll\", 'next', 'end', 'streets.', 'giv', 'bet', 'liv', 'streets', 'mon', 'without', 'luxury', 'hom', 'entertain', 'set', 'bathroom', 'pict', 'wal', 'comput', 'everyth', 'treas', 'see', \"'s\", 'lik', 'homeless', 'goddard', 'bolt', \"'s\", 'lesson.', 'mel', 'brook', 'direct', 'star', 'bolt', 'play', 'rich', 'man', 'everyth', 'world', 'decid', 'mak', 'bet', 'sissy', 'riv', 'jeffery', 'tamb', 'see', 'liv', 'streets', 'thirty', 'day', 'without', 'luxury', 'bolt', 'success', 'want', 'fut', 'project', 'mak', 'build', 'bet', \"'s\", 'bolt', 'thrown', 'street', 'bracelet', 'leg', 'monit', 'every', 'mov', 'ca', \"n't\", 'step', 'sidewalk', \"'s\", 'giv', 'nicknam', 'pepto', 'vagr', \"'s\", 'writ', 'forehead', 'bolt', 'meet', 'charact', 'includ', 'wom', 'nam', 'mol', 'lesley', 'an', 'war', 'ex-dancer', 'got', 'divorc', 'los', 'hom', 'pal', 'sail', 'howard', 'mor', 'fum', 'teddy', 'wilson', 'already', 'us', 'streets', \"'re\", 'surv', 'bolt', \"n't\", \"'s\", 'us', 'reach', 'mut', 'agr', 'lik', 'rich', \"'s\", 'fight', 'flight', 'kil', 'killed.', 'lov', 'connect', 'mol', 'bolt', \"n't\", 'necess', 'plot', 'found', '``', 'lif', 'stink', \"''\", 'on', 'mel', 'brook', 'observ', 'film', 'pri', 'comedy', 'show', 'tend', 'sid', 'comp', 'slapstick', 'work', 'blaz', 'saddl', 'young', 'frankenstein', 'spacebal', 'mat', 'show', \"'s\", 'lik', 'someth', 'valu', 'los', 'next', 'day', 'hand', 'mak', 'stupid', 'bet', 'lik', 'rich', 'peopl', \"n't\", 'know', 'money', 'mayb', 'giv', 'homeless', 'instead', 'us', 'lik', 'monopo', 'money.', 'mayb', 'film', 'inspir', 'help', 'oth']\n"
     ]
    }
   ],
   "source": [
    "lemmatized_unigrams = apply_to_corpus(apply_lemmatization, corpus_unigrams)\n",
    "stemmed_unigrams = apply_to_corpus(apply_stemming, corpus_unigrams)\n",
    "print(lemmatized_unigrams[0])\n",
    "print(stemmed_unigrams[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set about generating a shared vocabulary, containing the number of documents each unique word occurs in, in order to calculate TF and IDF values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shared_vocabulary(corpus):\n",
    "    words = {}\n",
    "    for text in corpus:\n",
    "        for word in set(text): \n",
    "            # set(text) removes duplicates, meaning the dictionary contains document frequency values \n",
    "            # (number of documents our word occurs in)\n",
    "            if word in words:\n",
    "                words[word] += 1\n",
    "            else:\n",
    "                words[word] = 1\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_vocabulary = generate_shared_vocabulary(stemmed_unigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate our TF-IDF matrix, where each row represents a document in the corpus. We utilise the scipy sparse matrix data structure in order to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "def generate_tf_idf_matrix(corpus, shared_vocabulary, one_hot=False):\n",
    "    N = len(shared_vocabulary)\n",
    "    shared_vocabulary_list = list(shared_vocabulary)\n",
    "    matrix = sparse.lil_matrix(np.zeros([corpus_length, N]))\n",
    "    #sparse list of lists to store our tf_idf values\n",
    "\n",
    "    for i, text in enumerate(corpus):\n",
    "        for word in text: # calculate tf_idf for each feature in each document \n",
    "                          # and insert in correct index\n",
    "            index = shared_vocabulary_list.index(word)\n",
    "            tf = text.count(word) / len(text)\n",
    "            idf = np.log10(N / (shared_vocabulary[word] +1))\n",
    "            matrix[i, index] = tf * idf if not one_hot else 1\n",
    "            #if using one_hot vectors for SVM and LogReg then simply insert 1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01005802, 0.00693199, 0.01359507, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_unigram_tf_idf = generate_tf_idf_matrix(stemmed_unigrams, shared_vocabulary)\n",
    "stem_unigram_tf_idf[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2720, 29379)\n",
      "(800, 29379)\n",
      "(480, 29379)\n",
      "[0.        0.0105175 0.        ... 0.        0.        0.       ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "r_seed = 563\n",
    "np.random.seed(r_seed)\n",
    "\n",
    "def get_test_train_dev_split(X):\n",
    "    y = np.concatenate([np.ones(positive_labels), np.zeros(negative_labels)])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, \n",
    "                                                        shuffle=True, random_state=r_seed)\n",
    "    \n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, \n",
    "                                                        test_size=0.15, \n",
    "                                                       shuffle=True, random_state=r_seed)\n",
    "   \n",
    "    #we first split the data into train and test, then we split train into train \n",
    "    #and development\n",
    "    #68% train, 12% validation, 20% test\n",
    "    return X_train, y_train, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_dev, y_dev = get_test_train_dev_split(stem_unigram_tf_idf)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_dev.shape)\n",
    "print(X_train.toarray()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calculate_likelihood: calculates the likelihood that a feature x belongs to class C, p(x|C)\n",
    "labels: 1 for the class whose likelihood is being calculated, 0 for any others\n",
    "data: the training data, i.e. our TF-IDF matrix of all documents\n",
    "alpha: the alphas value for laplace smoothing\n",
    "'''\n",
    "def calculate_likelihoods(data, labels, alpha=1.0):\n",
    "    N = data.shape[1]\n",
    "    likelihoods = np.zeros([N])\n",
    "    for i in range(N):\n",
    "        feature = data[:, i].toarray().flatten()\n",
    "        likelihoods[i] = (np.sum(feature * labels) + alpha)  / (np.sum(labels) + alpha) \n",
    "        # likelihood calculation (p(X|C)) using laplace smoothing\n",
    "    return likelihoods\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#calculates the likelihoods for both classes given the training data\n",
    "#as well as priors for both classes\n",
    "#inverted_y_train: an inverted label array, denoting 1 for the negative class and 0 for the positive\n",
    "#used in calculating likelihood and priors\n",
    "'''\n",
    "def train_multinomial_bayes(X_train, y_train):\n",
    "    inverted_y_train = np.array([not y for y in y_train]).astype(int)\n",
    "    \n",
    "    pos_likelihoods = calculate_likelihoods(X_train, y_train)\n",
    "    neg_likelihoods = calculate_likelihoods(X_train, inverted_y_train)\n",
    "    pos_log_likelihoods = np.log(pos_likelihoods)\n",
    "    neg_log_likelihoods = np.log(neg_likelihoods)\n",
    "\n",
    "    pos_prior = np.sum(y_train) / len(y_train)\n",
    "    neg_prior = np.sum(inverted_y_train) / len(inverted_y_train)\n",
    "    pos_log_prior = np.log(pos_prior)\n",
    "    neg_log_prior = np.log(neg_prior)\n",
    "    return pos_log_likelihoods, neg_log_likelihoods, pos_log_prior, neg_log_prior\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigns a class label to a given document using likelihoods and priors\n",
    "def get_multinomial_class_label(data, document):\n",
    "    pos_log_likelihoods, neg_log_likelihoods, pos_log_prior, neg_log_prior = data\n",
    "    #unpacks our sparse vector:\n",
    "    features = np.nonzero(document)[0] \n",
    "    pos_total = 0\n",
    "    neg_total = 0\n",
    "    for index in features: \n",
    "        #sum log likelihoods for each feature, for both classes\n",
    "        pos_total += pos_log_likelihoods[index]\n",
    "        neg_total += neg_log_likelihoods[index]\n",
    "    #add priors\n",
    "    pos_total += pos_log_prior \n",
    "    neg_total += neg_log_prior\n",
    "    class_label = 1 if pos_total > neg_total else 0 \n",
    "    return class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs the entire pipeline for MNB and returns a predictions array\n",
    "def test_train_multinomial_bayes(train_data, train_labels, test_data):\n",
    "    data = train_multinomial_bayes(train_data, train_labels)\n",
    "    predictions = []\n",
    "    for i, v in enumerate(test_data):\n",
    "        doc =  test_data[i].toarray().flatten()\n",
    "        label = get_multinomial_class_label(data, doc)\n",
    "        predictions.append(label)\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model( test_labels, predictions):\n",
    "    print(\"accuracy:\", accuracy_score(test_labels, predictions))\n",
    "    print(\"precision:\", precision_score(test_labels, predictions))\n",
    "    print(\"recall:\", recall_score(test_labels, predictions))\n",
    "    print(\"f1 score:\", f1_score(test_labels, predictions))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation for Multinomial Naive Bayes on the development set for stemmed unigrams: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5025735294117647 0.4974264705882353\n",
      "accuracy: 0.875\n",
      "precision: 0.9267015706806283\n",
      "recall: 0.7937219730941704\n",
      "f1 score: 0.8550724637681159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = test_train_multinomial_bayes(X_train, y_train, X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calculate_guassian_distributions: calculates the mean and standard distribution for \n",
    "a given feature using TF-IDF scores across all documents\n",
    "labels: 1 for the class whose likelihood is being calculated, 0 for any others\n",
    "data: the training data, i.e. our TF-IDF matrix of all documents\n",
    "alpha: the alphas value for laplace smoothing\n",
    "'''\n",
    "def calculate_guassian_distributions(data, labels, alpha=1e-10):\n",
    "    pos_distribution = []\n",
    "    neg_distribution = []\n",
    "    inverted_labels = np.array([not y for y in labels]).astype(int)\n",
    "\n",
    "    for i in range(data.shape[1]): #calculate means and standard deviations for each feature\n",
    "                                   #in order to compute distributions\n",
    "        feature = data[:, i].toarray().flatten() \n",
    "        #collects the instances of the feature being present in a positive and negative class resp.\n",
    "        pos_feature = feature * labels\n",
    "        neg_feature = feature * inverted_labels\n",
    "        pos_distribution.append((np.mean(pos_feature) + alpha, np.std(pos_feature) + alpha))\n",
    "        neg_distribution.append((np.mean(neg_feature) + alpha, np.std(neg_feature) + alpha))\n",
    "    return pos_distribution, neg_distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#calculates the likelihoods for both classes given the training data\n",
    "#as well as priors for both classes\n",
    "#inverted_y_train: an inverted label array, denoting 1 for the negative class and 0 for the positive\n",
    "#used in calculating likelihood and priors\n",
    "'''\n",
    "def train_gaussian_bayes(X_train, y_train):\n",
    "    inverted_y_train = np.array([not y for y in y_train]).astype(int)\n",
    "\n",
    "    pos_distribution, neg_distribution = calculate_guassian_distributions(X_train, y_train)\n",
    "    pos_log_distribution = np.log(pos_distribution)\n",
    "    neg_log_distribution = np.log(neg_distribution)\n",
    "\n",
    "    pos_prior = np.sum(y_train) / len(y_train)\n",
    "    neg_prior = np.sum(inverted_y_train) / len(inverted_y_train)\n",
    "    pos_log_prior = np.log(pos_prior)\n",
    "    neg_log_prior = np.log(neg_prior)\n",
    "\n",
    "    return pos_log_distribution, neg_log_distribution, pos_log_prior, neg_log_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fits value (the TF-IDF score for a given feature in the input document) to the guassian distribution of said feature \n",
    "def gaussian(mean, sd, value):\n",
    "    exponent = (- (value - mean)**2 ) / (2 * sd**2)\n",
    "    value = (1 / np.sqrt(2 * np.pi * sd**2)) * np.exp(exponent)\n",
    "    if np.isnan(value): #0 if NaN\n",
    "        return 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produces a class label for a given document using our GNB\n",
    "def get_gaussian_class_label(data, document):\n",
    "    pos_distribution, neg_distribution, pos_log_prior, neg_log_prior = data\n",
    "    features = np.nonzero(document)[0]\n",
    "    pos_total = 0\n",
    "    neg_total = 0\n",
    "    for index in features: #calculates the likelihood using the mean, sd, and value for each feature\n",
    "                           #gaussian(mean, sd, x)\n",
    "                           #pos_distribution[i] = (mean, sd), where i is feature index\n",
    "        pos_total += gaussian(pos_distribution[index][0], pos_distribution[index][1], \n",
    "                            document[index] ) \n",
    "        neg_total += gaussian(neg_distribution[index][0], neg_distribution[index][1],\n",
    "                            document[index] ) \n",
    "    pos_total += pos_log_prior\n",
    "    neg_total += neg_log_prior\n",
    "    label = 1 if pos_total > neg_total else 0\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full GNB pipeline\n",
    "def test_train_gaussian_bayes(train_data, train_labels, test_data):\n",
    "    data = train_gaussian_bayes(train_data, train_labels)\n",
    "    predictions = []\n",
    "    for i, v in enumerate(test_data):\n",
    "        doc =  test_data[i].toarray().flatten()\n",
    "        label = get_gaussian_class_label(data, doc)\n",
    "        predictions.append(label)\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on development set for Guassian Bayes using stemmed unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8645833333333334\n",
      "precision: 0.8291666666666667\n",
      "recall: 0.8923766816143498\n",
      "f1 score: 0.8596112311015119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = test_train_gaussian_bayes(X_train, y_train, X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sklearn MNB and GNB Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Multinomial Bayes\n",
      "accuracy: 0.85625\n",
      "precision: 0.8155737704918032\n",
      "recall: 0.8923766816143498\n",
      "f1 score: 0.8522483940042827\n",
      "\n",
      "Sklearn Gaussian Bayes\n",
      "accuracy: 0.65\n",
      "precision: 0.611336032388664\n",
      "recall: 0.6771300448430493\n",
      "f1 score: 0.6425531914893617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def test_train_sklearn_models(X_train, y_train, X_test, y_test):\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(\"Sklearn Multinomial Bayes\")\n",
    "    evaluate_model(y_test, predictions)\n",
    "\n",
    "    clf2 = GaussianNB()\n",
    "    clf2.fit(X_train.toarray(), y_train)\n",
    "    predictions = clf2.predict(X_test.toarray())\n",
    "    print(\"Sklearn Gaussian Bayes\")\n",
    "    evaluate_model(y_test, predictions)\n",
    "test_train_sklearn_models(X_train, y_train, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For stemmed unigrams our own implementation of multinomial bayes achieves a similar accuracy and f1score, higher precision and a lower recall in comparison to the prebuilt sklearn model. Own implementation of Gaussian Bayes far outperforms on accuracy, precision, and f1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full training and evaluation for a given corpus using all models\n",
    "def evaluate_on_corpus(corpus):\n",
    "    shared_vocabulary = generate_shared_vocabulary(corpus)\n",
    "    tf_idf_matrix = generate_tf_idf_matrix(corpus, shared_vocabulary)\n",
    "    X_train, y_train, X_test, y_test, X_dev, y_dev = get_test_train_dev_split(tf_idf_matrix)\n",
    "\n",
    "    multinomial_predictions = test_train_multinomial_bayes(X_train, y_train, X_dev)\n",
    "    print(\"Multinomial Bayes\")\n",
    "    evaluate_model(y_dev, multinomial_predictions)\n",
    "    gaussian_predictions = test_train_gaussian_bayes(X_train, y_train, X_dev)\n",
    "    print(\"Gaussian Bayes\")\n",
    "    evaluate_model(y_dev, gaussian_predictions)\n",
    "    test_train_sklearn_models(X_train, y_train, X_dev, y_dev)\n",
    "    return tf_idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we ran stemmed and lemmatized bigrams and produced the following results. These are omitted as code cells due to the time taken to run (> 90 minutes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lemmatized_bigrams = apply_to_corpus(apply_lemmatization, corpus_bigrams) <br>\n",
    "evaluate_on_corpus(lemmatized_bigrams) <br>\n",
    "<br>\n",
    "Lemmatized Bigrams:<br>\n",
    "<br>\n",
    "Multinomial Bayes<br>\n",
    "accuracy: 0.555<br>\n",
    "precision: 0.9666666666666667<br>\n",
    "recall: 0.07552083333333333<br>\n",
    "f1 score: 0.1400966183574879<br>\n",
    "<br>\n",
    "Gaussian Bayes<br>\n",
    "accuracy: 0.74375<br>\n",
    "precision: 0.6660482374768089<br>\n",
    "recall: 0.9348958333333334<br>\n",
    "f1 score: 0.7778981581798483<br>\n",
    "<br>\n",
    "<br>\n",
    "Stemmed Bigrams:<br>\n",
    "Multinomial Bayes<br>\n",
    "accuracy: 0.6375<br>\n",
    "precision: 0.8955223880597015<br>\n",
    "recall: 0.2643171806167401<br>\n",
    "f1 score: 0.40816326530612246<br>\n",
    "<br>\n",
    "Gaussian Bayes<br>\n",
    "accuracy: 0.7729166666666667<br>\n",
    "precision: 0.7341269841269841<br>\n",
    "recall: 0.8149779735682819<br>\n",
    "f1 score: 0.7724425887265136<br>\n",
    "<br>\n",
    "Sklearn Multinomial Bayes<br>\n",
    "accuracy: 0.7958333333333333<br>\n",
    "precision: 0.7698744769874477<br>\n",
    "recall: 0.8105726872246696<br>\n",
    "f1 score: 0.7896995708154506<br>\n",
    "<br>\n",
    "Sklearn Gaussian Bayes<br>\n",
    "accuracy: 0.7229166666666667<br>\n",
    "precision: 0.706140350877193<br>\n",
    "recall: 0.7092511013215859<br>\n",
    "f1 score: 0.7076923076923076<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having tried stemmed unigrams let's asses the use of lemmatized unigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Bayes\n",
      "accuracy: 0.8666666666666667\n",
      "precision: 0.9392265193370166\n",
      "recall: 0.7623318385650224\n",
      "f1 score: 0.8415841584158416\n",
      "\n",
      "Gaussian Bayes\n",
      "accuracy: 0.8666666666666667\n",
      "precision: 0.8326359832635983\n",
      "recall: 0.8923766816143498\n",
      "f1 score: 0.8614718614718615\n",
      "\n",
      "Sklearn Multinomial Bayes\n",
      "accuracy: 0.8645833333333334\n",
      "precision: 0.8464912280701754\n",
      "recall: 0.8654708520179372\n",
      "f1 score: 0.8558758314855874\n",
      "\n",
      "Sklearn Gaussian Bayes\n",
      "accuracy: 0.6354166666666666\n",
      "precision: 0.5930232558139535\n",
      "recall: 0.6860986547085202\n",
      "f1 score: 0.6361746361746361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lemmatized_unigrams = apply_to_corpus(apply_lemmatization, corpus_unigrams)\n",
    "lem_unigrams_tf_idf = evaluate_on_corpus(lemmatized_unigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly stemming achieves higher performance across the board. Let's try stemming without stopword removal and assess the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Bayes\n",
      "accuracy: 0.8020833333333334\n",
      "precision: 0.9266666666666666\n",
      "recall: 0.6233183856502242\n",
      "f1 score: 0.7453083109919572\n",
      "\n",
      "Gaussian Bayes\n",
      "accuracy: 0.8604166666666667\n",
      "precision: 0.8305084745762712\n",
      "recall: 0.8789237668161435\n",
      "f1 score: 0.8540305010893247\n",
      "\n",
      "Sklearn Multinomial Bayes\n",
      "accuracy: 0.8354166666666667\n",
      "precision: 0.7790697674418605\n",
      "recall: 0.9013452914798207\n",
      "f1 score: 0.8357588357588358\n",
      "\n",
      "Sklearn Gaussian Bayes\n",
      "accuracy: 0.65\n",
      "precision: 0.6122448979591837\n",
      "recall: 0.672645739910314\n",
      "f1 score: 0.6410256410256411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stemmed_unigrams_stopwords = apply_to_corpus(apply_stemming, corps_unigrams_with_stopwords)\n",
    "stem_uni_stopword_tf_idf = evaluate_on_corpus(stemmed_unigrams_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus our best feature set is unigrams with stemming. Let's now evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Bayes\n",
      "accuracy: 0.80875\n",
      "precision: 0.8768328445747801\n",
      "recall: 0.7292682926829268\n",
      "f1 score: 0.796271637816245\n",
      "\n",
      "Gaussian Bayes\n",
      "accuracy: 0.8275\n",
      "precision: 0.8105022831050228\n",
      "recall: 0.8658536585365854\n",
      "f1 score: 0.8372641509433961\n",
      "\n",
      "Sklearn Multinomial Bayes\n",
      "accuracy: 0.82\n",
      "precision: 0.8093023255813954\n",
      "recall: 0.848780487804878\n",
      "f1 score: 0.8285714285714286\n",
      "\n",
      "Sklearn Gaussian Bayes\n",
      "accuracy: 0.6525\n",
      "precision: 0.6578947368421053\n",
      "recall: 0.6707317073170732\n",
      "f1 score: 0.6642512077294686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, X_dev, y_dev = get_test_train_dev_split(stem_unigram_tf_idf)\n",
    "multinomial_predictions = test_train_multinomial_bayes(X_train, y_train, X_test)\n",
    "print(\"Multinomial Bayes\")\n",
    "evaluate_model(y_test, multinomial_predictions)\n",
    "gaussian_predictions = test_train_gaussian_bayes(X_train, y_train, X_test)\n",
    "print(\"Gaussian Bayes\")\n",
    "evaluate_model(y_test, gaussian_predictions)\n",
    "test_train_sklearn_models(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first compare one hot matrices to our usual TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_matrix = generate_tf_idf_matrix(stemmed_unigrams, shared_vocabulary, one_hot=True)\n",
    "print(one_hot_matrix[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8104166666666667"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, y_train, X_test, y_test, X_dev, y_dev = get_test_train_dev_split(stem_unigram_tf_idf)\n",
    "clf = LogisticRegression(random_state=r_seed, solver=\"sag\")\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adame\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, X_dev, y_dev = get_test_train_dev_split(one_hot_matrix)\n",
    "clf = LogisticRegression(random_state=r_seed, solver=\"sag\")\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly one hot matrices lead to higher performance. Let's try evaluating for stemmed unigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8333333333333334\n",
      "precision: 0.8122270742358079\n",
      "recall: 0.8340807174887892\n",
      "f1 score: 0.8230088495575221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try for lemmatized unigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8583333333333333\n",
      "precision: 0.8414096916299559\n",
      "recall: 0.8565022421524664\n",
      "f1 score: 0.8488888888888888\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adame\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lem_uni_one_hot = generate_tf_idf_matrix(lemmatized_unigrams, \n",
    "                                         generate_shared_vocabulary(lemmatized_unigrams), one_hot=True)\n",
    "X_train, y_train, X_test, y_test, X_dev, y_dev = get_test_train_dev_split(lem_uni_one_hot)\n",
    "clf = LogisticRegression(random_state=r_seed, solver=\"sag\").fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemmed unigrams without stopword removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8375\n",
      "precision: 0.8111587982832618\n",
      "recall: 0.8475336322869955\n",
      "f1 score: 0.8289473684210525\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adame\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "stem_uni_stop_one_hot = generate_tf_idf_matrix(stemmed_unigrams_stopwords, \n",
    "                                               generate_shared_vocabulary(stemmed_unigrams_stopwords), one_hot=True)\n",
    "X_train, y_train, X_test, y_test, X_dev, y_dev = get_test_train_dev_split(stem_uni_stop_one_hot)\n",
    "clf = LogisticRegression(random_state=r_seed, solver=\"sag\")\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing feature set was thus lemmatization with stop-word removal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemmed unigrams with stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8520833333333333\n",
      "precision: 0.8247863247863247\n",
      "recall: 0.8654708520179372\n",
      "f1 score: 0.8446389496717724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "def svm_classifier(feature_matrix):\n",
    "    X_train, y_train, X_test, y_test, X_dev, y_dev = get_test_train_dev_split(feature_matrix)\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_dev)\n",
    "    evaluate_model(y_dev, predictions)\n",
    "svm_classifier(one_hot_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with lemmatized unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.85\n",
      "precision: 0.8212765957446808\n",
      "recall: 0.8654708520179372\n",
      "f1 score: 0.8427947598253275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_classifier(lem_uni_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with stemmed unigrams and no stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8520833333333333\n",
      "precision: 0.8247863247863247\n",
      "recall: 0.8654708520179372\n",
      "f1 score: 0.8446389496717724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_classifier(stem_uni_stop_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our highest performing set was lemmatization with stopword removal. Let's now optimise hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline performance with no hyperparameter tuning: <br>\n",
    "accuracy: 0.8583333333333333 <br> \n",
    "precision: 0.8414096916299559 <br>\n",
    "recall: 0.8565022421524664 <br>\n",
    "f1 score: 0.8488888888888888 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing regularization parameter C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8541666666666666\n",
      "precision: 0.84\n",
      "recall: 0.8475336322869955\n",
      "f1 score: 0.84375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#C=0.1\n",
    "X_train, y_train, X_test, y_test, X_dev, y_dev = get_test_train_dev_split(lem_uni_one_hot)\n",
    "clf = LogisticRegression(C=0.1, random_state=r_seed, solver=\"sag\")\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8583333333333333\n",
      "precision: 0.8414096916299559\n",
      "recall: 0.8565022421524664\n",
      "f1 score: 0.8488888888888888\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adame\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#C=1.5\n",
    "X_train, y_train, X_test, y_test, X_dev, y_dev = get_test_train_dev_split(lem_uni_one_hot)\n",
    "clf = LogisticRegression(C=1.5, random_state=r_seed, solver=\"sag\")\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C=1.5 clearly improves performance. Now testing different solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.85625\n",
      "precision: 0.8347826086956521\n",
      "recall: 0.8609865470852018\n",
      "f1 score: 0.847682119205298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#solver=\"liblinear\"\n",
    "clf = LogisticRegression(C=1.5, solver=\"liblinear\",random_state=r_seed)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8583333333333333\n",
      "precision: 0.8384279475982532\n",
      "recall: 0.8609865470852018\n",
      "f1 score: 0.8495575221238938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#solver=\"lbfgs\"\n",
    "clf = LogisticRegression(C=1.5, solver=\"lbfgs\", random_state=r_seed)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8583333333333333\n",
      "precision: 0.8414096916299559\n",
      "recall: 0.8565022421524664\n",
      "f1 score: 0.8488888888888888\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adame\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#solver=\"sag\"\n",
    "clf = LogisticRegression(C=1.5, solver=\"sag\",random_state=r_seed)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"lbfgs\" achieves the best performance. Now experimenting with different penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adame\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8479166666666667\n",
      "precision: 0.831858407079646\n",
      "recall: 0.8430493273542601\n",
      "f1 score: 0.8374164810690423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#penalty=None\n",
    "clf = LogisticRegression(C=1.5, solver=\"lbfgs\", random_state=r_seed,\n",
    "                         penalty=None)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8583333333333333\n",
      "precision: 0.8384279475982532\n",
      "recall: 0.8609865470852018\n",
      "f1 score: 0.8495575221238938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#penalty=\"l2\"\n",
    "clf = LogisticRegression(C=1.5, solver=\"lbfgs\", random_state=r_seed, \n",
    "                         penalty=\"l2\")\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A penalty of \"l2\" appears optimal, now attempting to parallelize with n_jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8583333333333333\n",
      "precision: 0.8384279475982532\n",
      "recall: 0.8609865470852018\n",
      "f1 score: 0.8495575221238938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#n_jobs=-1\n",
    "clf = LogisticRegression(C=1.5, solver=\"lbfgs\", random_state=r_seed, \n",
    "                         penalty=\"l2\", n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8583333333333333\n",
      "precision: 0.8384279475982532\n",
      "recall: 0.8609865470852018\n",
      "f1 score: 0.8495575221238938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#n_jobs=None\n",
    "clf = LogisticRegression(C=1.5, solver=\"lbfgs\", random_state=r_seed, \n",
    "                         penalty=\"l2\", n_jobs=None)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that parallelizing does not increase performance. Hyperparameter tuning is complete, giving us our fine tuned model:\n",
    "+ C = 1.5\n",
    "+ solver = \"lbfgs\"\n",
    "+ penalty = \"l2\"\n",
    "+ n_jobs = None (i.e. not parallelized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.83625\n",
      "precision: 0.8329355608591885\n",
      "recall: 0.8512195121951219\n",
      "f1 score: 0.8419782870928829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "evaluate_model(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SVM Hyperparameters </h1><br>\n",
    "Baseline performance of untuned model: <br>\n",
    "accuracy: 0.8520833333333333 <br>\n",
    "precision: 0.8247863247863247 <br>\n",
    "recall: 0.8654708520179372 <br>\n",
    "f1 score: 0.8446389496717724 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing different values for regulariation parameter C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_dev, y_dev = get_test_train_dev_split(one_hot_matrix)\n",
    "clf = svm.SVC(C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8520833333333333\n",
      "precision: 0.8220338983050848\n",
      "recall: 0.8699551569506726\n",
      "f1 score: 0.8453159041394336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C=0.9)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = 0.9 slightly outperforms the default C = 1, now testing different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8166666666666667\n",
      "precision: 0.8\n",
      "recall: 0.8071748878923767\n",
      "f1 score: 0.8035714285714287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C=0.9, kernel=\"linear\")\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=0.9, kernel=\"rbf\")\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"rbf\" kernel achieves the best perfomance, now testing different gamma configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=0.9, kernel=\"rbf\", gamma=\"auto\")\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=0.9, kernel=\"rbf\", gamma=\"scale\")\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_dev)\n",
    "evaluate_model(y_dev, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma=\"scale\" appears to performe the best, giving us our final tuned model:\n",
    "+ C = 0.9\n",
    "+ kernel = \"rbf\" \n",
    "+ gamma = \"scale\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.82625\n",
      "precision: 0.8086560364464692\n",
      "recall: 0.8658536585365854\n",
      "f1 score: 0.8362779740871613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "evaluate_model(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>BERT Results</h1>\n",
    "Our BERT experiments are contained in another notebook however we have included the results here for comparitive purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BERT-UNCASED: DEV SET\n",
    "accuracy: 0.8458333333333333\n",
    "precision: 0.8311111111111111\n",
    "recall: 0.8385650224215246\n",
    "f1 score: 0.8348214285714286\n",
    "\n",
    "TEST SET\n",
    "accuracy: 0.89125\n",
    "precision: 0.8891566265060241\n",
    "recall: 0.9\n",
    "f1 score: 0.8945454545454546\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BERT CASED DEV SET\n",
    "accuracy: 0.84375\n",
    "precision: 0.8032786885245902\n",
    "recall: 0.8789237668161435\n",
    "f1 score: 0.8394004282655245\n",
    "\n",
    "\n",
    "TEST SET\n",
    "accuracy: 0.8825\n",
    "precision: 0.8657407407407407\n",
    "recall: 0.9121951219512195\n",
    "f1 score: 0.8883610451306413\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
